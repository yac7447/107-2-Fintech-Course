{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QAI\n",
      "MNA\n",
      "WTMF\n",
      "FTLS\n",
      "DYLS\n",
      "RLY\n",
      "DIVY\n",
      "CPI\n",
      "HTUS\n",
      "BTAL\n",
      "HDG\n",
      "VAMO\n",
      "QMN\n",
      "FLAG\n",
      "FMF\n",
      "RALS\n",
      "MOM\n",
      "ALTS\n",
      "MCRO\n",
      "QLS\n",
      "MRGR\n",
      "DIVA\n",
      "QED\n",
      "SIZ\n",
      "CHEP\n",
      "SVXY\n",
      "TVIX\n",
      "UVXY\n",
      "VIXY\n",
      "ZIV\n",
      "VIXM\n",
      "VIIX\n",
      "XVZ\n"
     ]
    }
   ],
   "source": [
    "#read excel files for the list of ETFs, get symbol, ETF name and asset class \n",
    "etf = pd.read_excel('ETF_Vol_Alt_list_Group16.xlsx', 'ETF list',usecols='A:C')\n",
    "symbols=etf['Symbol']\n",
    "\n",
    "#use symbols to crawl etfdb.com and get info of issuer and link of fund homepage\n",
    "\n",
    "data = list()\n",
    "all_data = list()\n",
    "\n",
    "for symbol in symbols :\n",
    "    print(symbol)\n",
    "    url='https://etfdb.com/etf/'+symbol\n",
    "    res = requests.get(url)\n",
    "    soup = bs(res.text,features='html.parser')\n",
    "    for FindHomepage in soup.find_all(\"a\", text=\"Home page\"):\n",
    "        homepage = FindHomepage.get('href')\n",
    "    for FindIssuer in soup.find_all(href=re.compile(\"/issuer/\")):\n",
    "        issuer = FindIssuer.string\n",
    "    data.append({'Symbol' : symbol,\n",
    "                 'Issuer' : issuer, \n",
    "                 'Home page' : homepage})\n",
    "    time.sleep(3)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine dataframe and write to excel\n",
    "\n",
    "df2 = pd.DataFrame(data)\n",
    "df1 = pd.DataFrame(etf)\n",
    "\n",
    "df = pd.merge(df1, df2,on = 'Symbol')\n",
    "df.set_index('Symbol', inplace=True)\n",
    "\n",
    "df.to_excel('ETF_Vol_Alt_Group16.xlsx', sheet_name='Updated ETF list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crawl historical NAV from fund home page\n",
    "\n",
    "for symbol in symbols :\n",
    "    url = df.at[symbol, 'Home page']\n",
    "    issuer = df.at[symbol, 'Issuer']\n",
    "    if issuer == 'ProShares':\n",
    "        res = requests.get(url)\n",
    "        soup = bs(res.text,features='html.parser')\n",
    "        for FindLink in soup.find_all(href=re.compile(\"historical_nav\")):\n",
    "            link = FindLink.get('href')\n",
    "            wget.download(link, symbol + \".csv\")\n",
    "            print(\"download: \" + symbol)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
