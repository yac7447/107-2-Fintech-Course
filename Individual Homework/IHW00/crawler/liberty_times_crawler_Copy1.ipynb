{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe that we can get news of a day with the link format:\n",
    "http://news.ltn.com.tw/list/newspaper/politics/20181231\n",
    "#### We need a list of date string in the date range we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_date = \"2018-11-16\"\n",
    "stop_date = \"2018-11-30\"\n",
    "\n",
    "start = datetime.strptime(start_date, \"%Y-%m-%d\")\n",
    "stop = datetime.strptime(stop_date, \"%Y-%m-%d\")\n",
    "\n",
    "#Listing dates in the defined period\n",
    "dates = list()\n",
    "while start <= stop:\n",
    "    dates.append(start.strftime('%Y%m%d'))\n",
    "    start = start + timedelta(days=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now write a function to parse the HTML response, return the data we want(title, content, ...etc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_document(document, date):\n",
    "    \n",
    "    nodes = document.select('ul.list > li')\n",
    "    data = list()\n",
    "\n",
    "    for li in nodes:\n",
    "\n",
    "        # check if is empty element\n",
    "        if li.select_one('a') == None:\n",
    "            continue\n",
    "\n",
    "        # get link\n",
    "        li_link = 'http://news.ltn.com.tw/' + li.select_one('a')['href']\n",
    "\n",
    "        # request for document\n",
    "        li_res = requests.get(li_link)\n",
    "        li_doc = bs(li_res.text, 'lxml')\n",
    "\n",
    "        # get date\n",
    "        li_date = datetime.strptime(date, \"%Y%m%d\").strftime('%Y-%m-%d')\n",
    "\n",
    "        #get title\n",
    "        li_title = li.select_one('p').get_text()\n",
    "\n",
    "        #get content\n",
    "        li_content = \"\"\n",
    "        for ele in li_doc.select('div.text > p'):\n",
    "            if not 'appE1121' in ele.get('class', []):\n",
    "                li_content += ele.get_text()\n",
    "\n",
    "        # append new row\n",
    "        data.append({\n",
    "            'date' : li_date,\n",
    "            'title': li_title,\n",
    "            'link' : li_link,\n",
    "            'content' : li_content,\n",
    "            'tags' : []\n",
    "        })\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Crawl over the news on the site, store the data in variable \"all_data\" ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start crawling : 20181116\n",
      "start crawling : 20181117\n",
      "start crawling : 20181118\n",
      "start crawling : 20181119\n",
      "start crawling : 20181120\n",
      "start crawling : 20181121\n",
      "start crawling : 20181122\n",
      "start crawling : 20181123\n",
      "start crawling : 20181124\n",
      "start crawling : 20181125\n",
      "start crawling : 20181126\n",
      "start crawling : 20181127\n",
      "start crawling : 20181128\n",
      "start crawling : 20181129\n",
      "start crawling : 20181130\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "all_data = list()\n",
    "#Crawling and return data for all the dates in the list of dates created before\n",
    "for date in dates:\n",
    "    print('start crawling :', date)\n",
    "    res = requests.get('https://news.ltn.com.tw/list/newspaper/politics/' + date)\n",
    "    doc = bs(res.text, 'lxml')\n",
    "    data = process_document(doc, date)\n",
    "    all_data += data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'date': '2018-11-16',\n",
       "  'title': '丁姚批操弄棄保 柯︰我啞巴吃黃連',\n",
       "  'link': 'http://news.ltn.com.tw/news/politics/paper/1247168',\n",
       "  'content': '〔記者黃建豪、簡惠茹、周彥妤／台北報導〕台北市長選舉白熱化，面對國民黨台北市長候選人丁守中攻擊「白綠合謀」、「棄姚保柯」，民進黨台北市長候選人姚文智指控操弄柯妻陳佩琪發文「棄保」，台北市長柯文哲昨天受訪反嗆，在台灣政治的藍綠兩極對立氛圍下，丁守中跟姚文智眼中只有藍綠、陰謀論和貼標籤，讓他只能啞巴吃黃連。對於丁守中連日指出民進黨與柯文哲合謀，操作「棄姚保柯」，民進黨主席蔡英文是「詐騙集團首腦」，姚昨回批，選擇丁守中就是選馬英九，也是選擇「侵占不當黨產」，讓公義無法實現，更等同選擇「追求與中國統一的混蛋」。姚強調，從前柯市府的官員蘇麗瓊、李文英及簡余晏表態支持他的案例看來，「棄柯保姚」才正發酵。丁守中昨天再度向中間選民喊話，批評民進黨衝撞兩岸搞糟台灣經濟，柯文哲只會講「空話、大話、幹話」，毫無建設、作秀不做事；若要棄保，也是「棄柯保丁」或「棄姚保丁」。丁陣營也強調，希望選舉坦坦蕩蕩、光明磊落，不要玩弄藍綠、不要玩弄棄保，民主政治反對「家天下」，也拜託不要「家台北」，柯文哲一家人聯手玩「棄保效應」。柯文哲夫人陳佩琪日前於臉書發文稱「沒有人須要為一次選舉的失敗而永遠退出政壇」 ，遭解讀為「柯文哲透過夫人操作棄保」，丁守中也批評「蔡英文是詐騙集團首腦，而姚文智只是車手」，柯文哲昨於內湖區傳統市場掃街時，再度被「棄保」議題圍繞。柯文哲抱怨，丁守中跟姚文智，眼中只有藍綠、心中只有陰謀論、手上只有貼標籤，所以他不管做什麼，雙方都在說陰謀論，從小野事件到現在，他都是啞巴吃黃連。',\n",
       "  'tags': []},\n",
       " {'date': '2018-11-16',\n",
       "  'title': '柯打告急牌「還是有可能會輸」',\n",
       "  'link': 'http://news.ltn.com.tw/news/politics/paper/1247169',\n",
       "  'content': '〔記者黃建豪、沈佩瑤／台北報導〕台北市長選情膠著，面對選舉氛圍回歸藍、綠對峙，在十一月以前，保持領先優勢的台北市長柯文哲昨坦言，情勢不利，在最後選舉衝刺階段，傳統政黨若發揮組織運作，將選票各自拉回一部分，他還是有可能落選。柯文哲說，整個台灣還是有城鄉差距，台北是台灣最領先的城市，整個政治發展起來，台北市最早開始有辦法讓藍、綠以外的東西生存，所以他呼籲，是不是給台北一個機會，台北有機會，台灣才有機會，像高雄打成這樣，就是藍綠的激烈對抗。柯文哲也說，他還是有可能（會輸），怎麼不可能？他也算過，政黨最後催票還是有它的實力，因為里長、後援會這種組織，依他上一次的經驗，除非他贏第二名超過一定比例，不然各政黨這裡拉一點、那裡拉一點，他就輸掉了。柯文哲昨一早連掃三市場，行動競選總部「PAPAGO」活動晚間到人聲鼎沸的西門町，柯展現十足親和力，拜票、握手、合照來者不拒，搶拍民眾一度癱瘓交通。柯文哲演講時難掩心情激動，指著不遠處的北門表示，那就是他上任台北市長後，市政改革的起點，真正實現了「軸線翻轉、舊城復興」。昨晚約湧入近兩千人的支持者高喊加油口號，歌手謝和弦也出席活動替柯「暖場」，柯幕僚、人氣王「學姊」黃瀞瑩還被拱上台唱歌，現場氣氛熱烈。柯也談到近期北市府調查外國觀光客來台北最想去那些地方，西門町的排名勝過故宮博物館，西門町是舊城區卻有最潮的次文化，他認為台灣真正的價值是民主、自由、多元、開放，應思考在地傳統如何跟新創文化結合。',\n",
       "  'tags': []},\n",
       " {'date': '2018-11-16',\n",
       "  'title': '合體三缺一 丁︰諒解韓苦衷',\n",
       "  'link': 'http://news.ltn.com.tw/news/politics/paper/1247170',\n",
       "  'content': '〔記者簡惠茹、楊心慧／台北報導〕國民黨高雄市長候選人韓國瑜巡迴全台助選，與新北市長候選人侯友宜多次同框，卻遲遲未與台北市長候選人丁守中合體，丁稱台北市長柯文哲對韓國瑜有「知遇之恩」，對此能諒解。韓昨天受訪強調，「感念柯文哲對我的情，但丁是同黨同志，有同志的愛」，並透露接下來的選舉不會離開高雄，等於宣告這場選戰不會替丁站台。韓國瑜與新北市長候選人侯友宜、台中市長候選人盧秀燕昨早在台中三都合體造勢，共同簽署「城市治理合作宣言」，丁守中再度被排除在外。丁守中昨天表示，大家各自全力衝刺，不一定要合體，各選區獲勝，就是國民黨最大的勝利；他也曾經聯繫韓國瑜，曉得韓的苦衷、考量，所以自己努力拚。韓過去受訪時曾坦言，國民黨內從來沒人像柯文哲一樣對他那麼重視，這點有和丁守中溝通過。針對丁說柯文哲曾經請韓做北農總經理，韓國瑜說，丁弄錯了，是郝龍斌市長任內。丁守中前天上廣播節目時曾說，柯文哲對於韓國瑜有知遇之恩，所以他能諒解。丁團隊補充說明，「柯文哲知遇之恩」是引用韓國瑜日前受訪的說法。',\n",
       "  'tags': []},\n",
       " {'date': '2018-11-16',\n",
       "  'title': '受辱讓母氣到發抖 姚哽咽落淚',\n",
       "  'link': 'http://news.ltn.com.tw/news/politics/paper/1247171',\n",
       "  'content': '〔記者周彥妤、簡惠茹／台北報導〕民進黨台北市長候選人姚文智昨與妻子潘瓊琪連袂赴大龍市場掃街。姚受訪憶起日前遭市長柯文哲母親何瑞英痛罵，自己的母親因心疼兒子受辱而悲憤交加，形單影隻「坐在陰暗客廳發抖」，姚一時情緒激動，哽咽落淚，姚妻默默替丈夫遞帕拭淚，不捨之情溢於言表。姚文智日前多次痛批柯文哲閃躲辯論會，何瑞英在重陽節反嗆姚「最沒路用、秤秤斤兩」等語，姚則回「祝柯媽媽重陽節快樂」；姚在本月十日辯論會上提及此事稱，自己的媽媽看到兒子挨罵難過不已，「氣到整天躲在陰暗客廳發抖」；何回應是姚先批評柯才回嘴，「回一句就受不了」，並反問姚，「罵人都不講，被罵才讓媽媽知道，這樣孝順嗎？」姚文智昨天由妻子陪同掃街拜票時表示，太太是他最大的安定力量；媒體詢問母親是否也會現身？姚突然沉默，哽咽流淚表示，他父母二○一四年都無私支持柯文哲，爸爸在去年過世，自己挨罵那天，媽媽獨自在老房子的陰暗客廳，看著電視新聞，氣到天黑還是一人坐在那，讓他難過、捨不得。此時，一旁的支持群眾替姚加油、打氣，姚妻潘瓊琪也拿手帕替姚拭淚安撫，不捨神情溢於言表。國民黨台北市長候選人丁守中昨批評，柯媽媽三天兩頭為了自己兒子，臭罵別人兒子「沒路用」，把姚文智都罵哭了，到底演哪齣戲啊？丁守中文中表示，啦啦隊親友團進場架拐子打對手，不是媽媽就是老婆，這組「婆媳關係」真是太特別了，這種「改變成真，持續發生」，真是太可怕了。',\n",
       "  'tags': []},\n",
       " {'date': '2018-11-16',\n",
       "  'title': '遭韓粉網軍霸凌 詹雅雯露面淚崩',\n",
       "  'link': 'http://news.ltn.com.tw/news/politics/paper/1247172',\n",
       "  'content': '〔記者陳心瑜／新北報導〕金曲歌后詹雅雯只因十一日在民進黨高雄市長候選人陳其邁的旗山造勢活動登台獻唱，她的臉書就遭韓粉網軍狂罵攻擊，詹雅雯多日足不出戶；網路霸凌風波後，她昨晚首度登台，到新北市淡水區為民進黨市議員候選人呂孫福的造勢晚會獻唱，一上台就受到民眾熱情歡迎，她泣訴從來沒有被人糟蹋、被人污辱成這樣，唱到一半不禁落淚，觀眾心疼大聲齊呼「雅雯我愛妳、加油！」、「挺你！」詹雅雯昨晚登台時，第一首《深情海岸》唱到一半，就忍不住哽咽，呂孫福趕緊遞上衛生紙，她在觀眾鼓勵下唱完《深情海岸》後，忍不住泣訴委屈，說到激動處淚流滿面。詹雅雯表示，自己是出外打拚的鄉下囝仔，工作就是唱歌、表演，明年就出道滿三十年，「從來沒有被人糟蹋、被人污辱成這樣！」她強調自己沒有做不對的事情，這幾天一直躲在家裡沒有出門，不是因為做錯事，而是要讓父母看得到自己，讓老人家放心；台下觀眾心疼大喊「雅雯我愛你」、「挺你！」不絕於耳。詹雅雯說，雖然事後了解是因誤會而遭攻擊，但她強調，不論黨派、階級或貧富，任何一個人決心要為民服務、為社會眾生服務，她都是懷著祝福的心，更不會因為特定黨派就接表演。她說，公司接的表演場合，電話一通通打來，她怎麼可能先問對方是信基督還是佛祖？是拜關公還是媽祖？只要商演、演出晚會沒有犯法，公司就會接下，「我不懂哪裡做錯了？」',\n",
       "  'tags': []}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save as pkl file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/liberty_times_copy_1.pkl'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-b288187eaf0e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/liberty_times_copy_1.pkl'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/liberty_times_copy_1.pkl'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('data/liberty_times_copy_1.pkl', 'wb') as f:\n",
    "    pickle.dump(all_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Turn it into pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(all_data)[['date', 'title', 'link', 'content', 'tags']].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
